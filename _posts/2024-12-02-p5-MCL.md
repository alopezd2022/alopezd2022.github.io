---
layout: post
title:  "P5 Monte Carlo Laser Localization"
tags: [mobile-robotics]
---

## Description

The objective of this practice is to develop the algorithm of Monte Carlo to localizate the robot.

## Monte Carlo Algorithm

#### Initialize
<div style="display: flex; align-items: center;">
    <img src="/assets/videos/p5/inicializar.gif" alt="GIF divertido" width="400" />
    <div style="margin-left: 20px; text-align: right;">
        <p>
            The particles are initialized with a uniform random distribution with a noise:
            <br>
            <strong>INIT_XY_STD = 0.5</strong> <br>
            <strong>INIT_ANGLE_STD = 0.1</strong>
        </p>
    </div>
</div>

&nbsp;

#### Step 1 Propagation (motion update)
<div style="display: flex; align-items: center;">
    <img src="/assets/videos/p5/propagacion.gif" alt="GIF divertido" width="400" />
    <div style="margin-left: 20px; text-align: right;">
        <p>
            The pose of particles move according to the movement of the robot with a little noise:
            <br>
            <strong>PROPAGATION_XY_NOISE_STD = 0.05</strong> <br>
            <strong>PROPAGATION_ANGLE_NOISE_STD = 0.01</strong>
        </p>
    </div>
</div>

&nbsp;

#### Step 2 Sensor update (weight estimation)

Following the Probabilistic Sensor Observation Model, the particles are assigned a weight depending on the difference between the laser sensor reading from the robot and a theoretical laser developed for each particle and each iteration. 

The calculation of the probabilities is given by the following formula :

<img src="/assets/images/p5/formula.png" alt="GIF divertido" width="400" />

Where the error represents the discrepancy between the actual sensor readings and the theoretical predictions for each particle, calculated based on their position and orientation in the map

The weights are normalized to ensure they form a probability distribution, making it easier to compare and interpret the likelihood of each particle accurately.

#### Step 3 Resampling

Select and give more importance to the most relevant particles, those which have more probability. Eliminating the irrelevant particles and duplicating the relevant ones

&nbsp;


### Solution
The most significant problem was the convergence of the particles, not because the algorithm wasn’t accurate, but because the computation time was very high, which did not allow for fast processing. Therefore, we can observe an initial solution without parallel processing and a final solution implementing parallel processing.

#### Result without multiprocessing

<div style="display: flex; align-items: center;">
    <video width="500" controls>
      <source src="{{ '/assets/videos/p5/sin_multi_video.mp4' | relative_url }}" type="video/webm">
      Tu navegador no soporta la reproducción de videos.
    </video>
    <div style="margin-left: 20px; text-align: right;">
        <p>
            As we can see in the video, the computation time is quite high. This prevents the algorithm from fully converging, as it requires fast processing. Using fewer        particles and fewer virtual ray traces reduces the computation time, but it is still not enough.
            <br>
            <strong>N_PARTICLES = 500</strong> <br>
            <strong>LASER_NUM_BEAMS = 3</strong>
        </p>
    </div>
</div>

&nbsp;

#### Result with multiprocessing

<div style="display: flex; align-items: center;">
    <video width="500" controls>
      <source src="{{ '/assets/videos/p5/multiprocesing_video.mp4' | relative_url }}" type="video/webm">
      Tu navegador no soporta la reproducción de videos.
    </video>
    <div style="margin-left: 20px; text-align: right;">
        <p>
            By the other side, using multiprocessing to execute the virtuals ray traces parallel show that the computation time reduce significantly. So we can increase the number of virtual ray traces.
            <br>
            <strong>N_PARTICLES = 500</strong> <br>
            <strong>LASER_NUM_BEAMS = 5</strong>
        </p>
    </div>
</div>
